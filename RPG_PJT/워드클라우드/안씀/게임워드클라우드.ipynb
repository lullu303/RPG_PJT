{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf74c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# # 크롤링할 사이트\n",
    "# url = \"https://www.google.com/search?q=%EC%BD%98%EC%86%94%EA%B2%8C%EC%9E%84+%ED%8A%B8%EB%A0%8C%EB%93%9C&ei=rSZbZOCfPIPl2roP-c-3wAE&ved=0ahUKEwigqtHX_en-AhWDslYBHfnnDRgQ4dUDCA8&uact=5&oq=%EC%BD%98%EC%86%94%EA%B2%8C%EC%9E%84+%ED%8A%B8%EB%A0%8C%EB%93%9C&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIECAAQHkoECEEYAFAAWABgiQFoAHABeACAAX2IAX2SAQMwLjGYAQCgAQHAAQE&sclient=gws-wiz-serp\"\n",
    "# # 요청 후 응답받기\n",
    "# html = urlopen(url)\n",
    "# # 파서 객체 생성\n",
    "# bs_obj = bs4.BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32065321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search keyword: 콘솔게임 트렌드\n"
     ]
    }
   ],
   "source": [
    "# keywords = input('Search keyword: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7d7921d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 윈도우용 웹드라이버 실행 경로\n",
    "excutable_path = \"chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a51d8e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jihye\\AppData\\Local\\Temp\\ipykernel_12300\\2780046001.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=excutable_path)\n",
      "C:\\Users\\jihye\\AppData\\Local\\Temp\\ipykernel_12300\\2780046001.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=excutable_path)\n"
     ]
    }
   ],
   "source": [
    "# 사이트의 html 구조에 기반하여 크롤링 수행\n",
    "driver = webdriver.Chrome(executable_path=excutable_path)\n",
    "\n",
    "# 크롤링할 사이트 주소 정의\n",
    "source_url = \"https://www.google.com/search?q=%EC%BD%98%EC%86%94%EA%B2%8C%EC%9E%84+%ED%8A%B8%EB%A0%8C%EB%93%9C&oq=&aqs=chrome.2.69i59i450l8.329291143j0j15&sourceid=chrome&ie=UTF-8\"\n",
    "\n",
    "# 사이트의 html 구조에 기반하여 크롤링 수행\n",
    "driver = webdriver.Chrome(executable_path=excutable_path)\n",
    "driver.get(source_url)\n",
    "req = driver.page_source\n",
    "soup = BeautifulSoup(req, \"html.parser\")\n",
    "contents_table = soup.find(name=\"table\")\n",
    "table_body = contents_table.find(name=\"tbody\")\n",
    "table_rows = table_body.find_all(name=\"tr\")\n",
    "\n",
    "page_url_base = \"https://google.com\"\n",
    "page_urls = []\n",
    "# class_url = soup.find_all('h3', class_ = \"LC201b MBeu0 DKV0Md\")\n",
    "\n",
    "for index in range(0, len(table_rows)) :\n",
    "    first_class = table_rows[index].find_all('MjjYud')\n",
    "    class_url = soup.find_all('h3', class_ = \"LC20lb MBeuO DKV0Md\")\n",
    "#     <h3 class=\"LC20lb MBeuO DKV0Md\">[지스타 2022] 내년 게임 트렌드 '콘솔·PC'…'덕후 게임'의 반란</h3>\n",
    "    if len(first_class) > 0 :\n",
    "        page_url = page_url_base + class_url[0].get('href')\n",
    "        if 'png' not in page_url :\n",
    "            page_urls.append(page_url)\n",
    "            \n",
    "# 중복 url 제거\n",
    "page_url = list(set(page_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "89a71138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page_url_base = \"https://google.com\"\n",
    "# page_urls = []\n",
    "# # class_url = soup.find_all('h3', class_ = \"LC201b MBeu0 DKV0Md\")\n",
    "\n",
    "# for index in range(0, len(table_rows)) :\n",
    "#     first_class = table_rows[index].find_all('MjjYud')\n",
    "#     class_url = soup.find_all('h3', class_ = \"LC201b MBeu0 DKV0Md\")\n",
    "#     if len(first_class) > 0 :\n",
    "#         page_url = page_url_base + class_url[0].get('href')\n",
    "#         if 'png' not in page_url :\n",
    "#             page_urls.append(page_url)\n",
    "            \n",
    "# # 중복 url 제거\n",
    "# page_url = list(set(page_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b20fedd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 브라우저 종료\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "80730a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, content_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 크롤링데이터 데이터프레임으로 만들기\n",
    "columns = ['title', 'content_text']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "for page_url in page_urls :\n",
    "    \n",
    "    # 사이트의 html 구조에 기반하여 크롤링 수행\n",
    "    driver = webdriver.Chrome(executable_path=excutable_path)\n",
    "    driver.get(page_url)\n",
    "    req = driver.page_source\n",
    "    soup = BeautifulSoup(req, \"html.parser\")\n",
    "    contents_table = soup.find(name=\"article\")\n",
    "    title = contents_table.find_all('h3')\n",
    "    \n",
    "    # 페이지 내 제목 정보에서 개행문자를 제거한 뒤 추출\n",
    "    if title is not None :\n",
    "        row_title = title.text.replace(\"\\n\", \" \")\n",
    "    else :\n",
    "        row_title = \"\"\n",
    "        \n",
    "    # 페이지 내 본문 정보에서 개행 문자를 제거한 뒤 추출\n",
    "    # 만약 없는 경우, 빈 문자열로 대체\n",
    "    \n",
    "    if content_paragraphs is not None :\n",
    "        for paragraphs in content_paragraphs :\n",
    "            if paragraphs is not None :\n",
    "                content_corpus_list.append(paragraphs.text.replace(\"\\n\",\" \"))\n",
    "            else :\n",
    "                content_corpus_list.append(\"\")\n",
    "    else :\n",
    "        content_corpus_list.append(\"\")\n",
    "        \n",
    "        \n",
    "    # 모든 정보를 하나의 데이터 프레임에 저장\n",
    "    row = [row_title, row_category, \"\".join(content_corpus_list)]\n",
    "    series = pd.Series(row, index=df.columns)\n",
    "    df = df.append(series, ignore_index=True)\n",
    "    \n",
    "    # 크롤링에 사용한 브라우저 종료\n",
    "    driver.close()\n",
    "    \n",
    "# 데이터 프레임 출력\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b56276d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
